{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JgQNzc5O1MQh"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from utils.object_detector import ObjectDetector\n",
        "from utils.template_matcher import TemplateMatcher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "detector = ObjectDetector()\n",
        "matcher = TemplateMatcher()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BFQd2X0M1Uc7"
      },
      "outputs": [],
      "source": [
        "if \"google.colab\" in str(get_ipython()):\n",
        "    from google.colab.patches import cv2_imshow\n",
        "\n",
        "    imshow = cv2_imshow\n",
        "else:\n",
        "\n",
        "    def imshow(img):\n",
        "        cv2.imshow(\"ImageWindow\", img)\n",
        "        cv2.waitKey()\n",
        "\n",
        "        cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fvbuM52Mqqiy"
      },
      "outputs": [],
      "source": [
        "img1  = cv2.imread('resources/img1.jpg')\n",
        "img2  = cv2.imread('resources/img4.jpg')\n",
        "img1 = cv2.resize(img1, None, fx=0.2, fy=0.2)\n",
        "img2 = cv2.resize(img2, None, fx=0.2, fy=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Qy8AJuTV2Kx6"
      },
      "outputs": [],
      "source": [
        "img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntzhvoMbmiKk"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntzhvoMbmiKk"
      },
      "source": [
        "## Detecting objects on a photo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "w7pOQVIYn9C-"
      },
      "outputs": [],
      "source": [
        "detected_objects, detected_cords = detector.detect_objects(img2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "25JlTWWKmp9s"
      },
      "outputs": [],
      "source": [
        "for i, obj in enumerate(detected_objects):\n",
        "  corners = detector.detect_corners(obj)\n",
        "  if len(corners > 0):\n",
        "    transformed_image = detector.perspective_transform(obj, corners)\n",
        "    detected_objects[i] = transformed_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25JlTWWKmp9s"
      },
      "source": [
        "### Idea is to create templates for matching different objects, so far:\n",
        " - Capitol\n",
        " - Any non reversed card (template for a card is just a random card)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ackEj2s4m5wc"
      },
      "outputs": [],
      "source": [
        "# classes = ['Capitol', 'Opponent Capitol', 'Unit', 'Opponent Unit', 'Support', 'Opponent Support', 'Deck', 'Opponent Deck']\n",
        "classes = ['Capitol', 'Unit', 'Support', 'Deck']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "buuXaB19m-9f"
      },
      "outputs": [],
      "source": [
        "capitol= cv2.imread('resources/capitol_template.png')\n",
        "capitol_opp = cv2.imread('resources/capitol_opp_template.png')\n",
        "unit = cv2.imread('resources/unit_template.png')\n",
        "unit_opp = cv2.imread('resources/unit_opp_template.png')\n",
        "support = cv2.imread('resources/support_template.png')\n",
        "support_opp = cv2.imread('resources/support_opp_template.png')\n",
        "deck = cv2.imread('resources/deck_template.png')\n",
        "deck_opp = cv2.imread('resources/deck_opp_template.png')\n",
        "\n",
        "templates = [capitol, capitol_opp, unit, unit_opp, support, support_opp, deck, deck_opp]\n",
        "# templates = [capitol, unit, support, deck]\n",
        "# for template in templates:\n",
        "#   imshow(template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Used templates:\n",
        "![Capitol template](resources/capitol_template.png)\n",
        "![Unit template](resources/unit_template.png)\n",
        "![Support template](resources/support_template.png)\n",
        "![Deck template](resources/deck_template.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ackEj2s4m5wc"
      },
      "source": [
        "## Matching templates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buuXaB19m-9f"
      },
      "source": [
        "Templates are scaled to size of detected object and then each template is matched to each object to return which objects match given template, instead of hard coded value we would like to explore determining objects by most simmilar template given some small threshold is passed to exclude noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "id": "uF9qqKFiqaqU",
        "outputId": "7073ef1b-dcb8-4e11-9957-73421a53d5a7"
      },
      "outputs": [],
      "source": [
        "for obj in detected_objects:\n",
        "  imshow(obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YdYdJcGilCuf"
      },
      "outputs": [],
      "source": [
        "determined_classes = matcher.match_templates(templates, detected_objects)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9fApuE3Unf4E"
      },
      "outputs": [],
      "source": [
        "imshow(matcher.draw_detections(img2, detected_cords, determined_classes, classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "shRH7t_tofFX"
      },
      "outputs": [],
      "source": [
        "video_path = 'resources/vid3.mp4'\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Couldn't open video.\")\n",
        "    exit()\n",
        "\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "output_video_path = 'outputs/video.avi'\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "frame_number = 0\n",
        "process_every_n_frames = 20  # Process every 5th frame\n",
        "deck_detected = False\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    if frame_number % process_every_n_frames == 0:\n",
        "        detected_objects, detected_cords = detector.detect_objects(frame)\n",
        "        for obj in detected_objects:\n",
        "           corners = detector.detect_corners(obj)\n",
        "           if len(corners > 0):\n",
        "                transformed_image = detector.perspective_transform(obj, corners)\n",
        "                detected_objects[i] = transformed_image\n",
        "        determined_classes = matcher.match_templates(templates, detected_objects)\n",
        "        detected_this_frame = False\n",
        "        for obj_class in determined_classes:\n",
        "          if np.argmax(obj_class) == 6 and obj_class[np.argmax(obj_class)] > 0.2:\n",
        "            deck_detected = True\n",
        "            detected_this_frame = True\n",
        "            break\n",
        "        if not detected_this_frame:\n",
        "          deck_detected = False\n",
        "    if not deck_detected:\n",
        "       cv2.putText(frame, \"Card Drawn!\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "    frame = matcher.draw_detections(frame, detected_cords, determined_classes, classes)\n",
        "\n",
        "    out.write(frame)\n",
        "\n",
        "    frame_number += 1\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to exit\n",
        "        break\n",
        "\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "cv2.destroyAllWindows()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
